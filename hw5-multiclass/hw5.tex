%% LyX 2.2.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[ruled]{article}
\usepackage{courier}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[letterpaper]{geometry}
\geometry{verbose}
\usepackage{color}
\usepackage{url}
\usepackage{algorithm2e}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[unicode=true,
 bookmarks=false,
 breaklinks=false,pdfborder={0 0 1},backref=section,colorlinks=true]
 {hyperref}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecommand{\LyX}{\texorpdfstring%
  {L\kern-.1667em\lower.25em\hbox{Y}\kern-.125emX\@}
  {LyX}}

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

\makeatother

\usepackage{listings}
\lstset{backgroundcolor={\color{white}},
basicstyle={\footnotesize\ttfamily},
breakatwhitespace=false,
breaklines=true,
captionpos=b,
commentstyle={\color{mygreen}},
deletekeywords={...},
escapeinside={\%*}{*)},
extendedchars=true,
frame=shadowbox,
keepspaces=true,
keywordstyle={\color{blue}},
language=Python,
morekeywords={*,...},
numbers=none,
numbersep=5pt,
numberstyle={\tiny\color{mygray}},
rulecolor={\color{black}},
showspaces=false,
showstringspaces=false,
showtabs=false,
stepnumber=1,
stringstyle={\color{mymauve}},
tabsize=2}
\begin{document}
\global\long\def\reals{\mathbf{R}}
 \global\long\def\integers{\mathbf{Z}}
\global\long\def\naturals{\mathbf{N}}
 \global\long\def\rationals{\mathbf{Q}}
\global\long\def\ca{\mathcal{A}}
\global\long\def\cb{\mathcal{B}}
 \global\long\def\cc{\mathcal{C}}
 \global\long\def\cd{\mathcal{D}}
\global\long\def\ce{\mathcal{E}}
\global\long\def\cf{\mathcal{F}}
\global\long\def\cg{\mathcal{G}}
\global\long\def\ch{\mathcal{H}}
\global\long\def\ci{\mathcal{I}}
\global\long\def\cj{\mathcal{J}}
\global\long\def\ck{\mathcal{K}}
\global\long\def\cl{\mathcal{L}}
\global\long\def\cm{\mathcal{M}}
\global\long\def\cn{\mathcal{N}}
\global\long\def\co{\mathcal{O}}
\global\long\def\cp{\mathcal{P}}
\global\long\def\cq{\mathcal{Q}}
\global\long\def\calr{\mathcal{R}}
\global\long\def\cs{\mathcal{S}}
\global\long\def\ct{\mathcal{T}}
\global\long\def\cu{\mathcal{U}}
\global\long\def\cv{\mathcal{V}}
\global\long\def\cw{\mathcal{W}}
\global\long\def\cx{\mathcal{X}}
\global\long\def\cy{\mathcal{Y}}
\global\long\def\cz{\mathcal{Z}}
\global\long\def\ind#1{1(#1)}
\global\long\def\pr{\mathbb{P}}

\global\long\def\ex{\mathbb{E}}
\global\long\def\var{\textrm{Var}}
\global\long\def\cov{\textrm{Cov}}
\global\long\def\sgn{\textrm{sgn}}
\global\long\def\sign{\textrm{sign}}
\global\long\def\kl{\textrm{KL}}
\global\long\def\law{\mathcal{L}}
\global\long\def\eps{\varepsilon}
\global\long\def\convd{\stackrel{d}{\to}}
\global\long\def\eqd{\stackrel{d}{=}}
\global\long\def\del{\nabla}
\global\long\def\loss{\ell}
\global\long\def\tr{\operatorname{tr}}
\global\long\def\trace{\operatorname{trace}}
\global\long\def\diag{\text{diag}}
\global\long\def\rank{\text{rank}}
\global\long\def\linspan{\text{span}}
\global\long\def\proj{\text{Proj}}
\global\long\def\argmax{\operatornamewithlimits{arg\, max}}
\global\long\def\argmin{\operatornamewithlimits{arg\, min}}
\global\long\def\bfx{\mathbf{x}}
\global\long\def\bfy{\mathbf{y}}
\global\long\def\bfl{\mathbf{\lambda}}
\global\long\def\bfm{\mathbf{\mu}}
\global\long\def\calL{\mathcal{L}}
\global\long\def\vw{\boldsymbol{w}}
\global\long\def\vx{\boldsymbol{x}}
\global\long\def\vxi{\boldsymbol{\xi}}
\global\long\def\valpha{\boldsymbol{\alpha}}
\global\long\def\vbeta{\boldsymbol{\beta}}
\global\long\def\vsigma{\boldsymbol{\sigma}}
\global\long\def\vmu{\boldsymbol{\mu}}
\global\long\def\vtheta{\boldsymbol{\theta}}
\global\long\def\vd{\boldsymbol{d}}
\global\long\def\vs{\boldsymbol{s}}
\global\long\def\vt{\boldsymbol{t}}
\global\long\def\vh{\boldsymbol{h}}
\global\long\def\ve{\boldsymbol{e}}
\global\long\def\vf{\boldsymbol{f}}
\global\long\def\vg{\boldsymbol{g}}
\global\long\def\vz{\boldsymbol{z}}
\global\long\def\vk{\boldsymbol{k}}
\global\long\def\va{\boldsymbol{a}}
\global\long\def\vb{\boldsymbol{b}}
\global\long\def\vv{\boldsymbol{v}}
\global\long\def\vy{\boldsymbol{y}}


\title{Machine Learning and Computational Statistics\\
Homework 5: Generalized Hinge Loss and Multiclass SVM}

\maketitle
\textbf{Due: Tuesday, April 11, 2017, at 10pm (Submit via Gradescope)}

\textbf{Instructions}: Your answers to the questions below, including
plots and mathematical work, should be submitted as a single PDF file.
It's preferred that you write your answers using software that typesets
mathematics (e.g. \LaTeX{}, \LyX{}, or MathJax via iPython), though
if you need to you may scan handwritten work. You may find the \href{https://github.com/gpoore/minted}{minted}
package convenient for including source code in your \LaTeX{} document.
If you are using \LyX{}, then the \href{https://en.wikibooks.org/wiki/LaTeX/Source_Code_Listings}{listings}
package tends to work better.


\section{Introduction}

The goal of this problem set is to get more comfortable with the multiclass
hinge loss and multiclass SVM. In several problems below, you are
asked to justify that certain functions are convex. For these problems,
you may use any of the rules about convex functions described in our
notes on Convex Optimization (\url{https://davidrosenberg.github.io/mlcourse/Notes/convex-optimization.pdf})
or in the Boyd and Vandenberghe book. In particular, you will need
to make frequent use of the following result: If $f_{1},\ldots,f_{m}:\reals^{n}\to\reals$
are convex, then their pointwise maximum
\[
f(x)=\max\left\{ f_{1}(x),\ldots,f_{m}(x)\right\} 
\]
 is also convex. 

\section{Convex Surrogate Loss Functions}

It's common in machine learning that the loss functions we really
care about lead to optimization problems that are not computationally
tractable. The $0/1$ loss for binary classification is one such example\footnote{Interestingly, if our hypothesis space is linear classifiers and we
are in the ``realizable'' case, which means that there is some hypothesis
that achieves $0$ loss (with the 0/1 loss), then we can efficiently
find a good hypothesis using linear programming. This is not difficult
to see: each data point gives a single linear constraint, and we are
looking for a vector that satisfies the constraints for each data
point.}. Since we have better machinery for minimizing convex functions,
a standard approach is to find a \textbf{convex surrogate loss function.
}A convex surrogate loss function is a convex function that is an
upper bound for the loss function of interest\footnote{At this level of generality, you might be wondering: ``A convex function
of WHAT?''. For binary classification, we usually are talking about
a convex function of the margin. But to solve our machine learning
optimization problems, we will eventually need our loss function to
be a convex function of some $w\in\reals^{d}$ that parameterizes
our hypothesis space. It'll be clear in what follows what we're talking
about.}. If we can make the upper bound small, then the loss we care about
will also be small\footnote{This is actually fairly weak motivation for a convex surrogate. Much
better motivation comes from the more advanced theory of \textbf{classification
calibrated} loss functions. See Bartlett et al's paper ``Convexity,
Classification, and Risk Bounds.'' \url{http://www.eecs.berkeley.edu/~wainwrig/stat241b/bartlettetal.pdf}}. Below we will show that the multiclass hinge loss based on a class-sensitive
loss $\Delta$ is a convex surrogate for the multiclass loss function
$\Delta$, when we have a linear hypothesis space. We'll start with
a special case, that the hinge loss is a convex surrogate for the
$0/1$ loss.

\subsection{Hinge loss is a convex surrogate for 0/1 loss}
\begin{enumerate}
\item Let $f:\cx\to\reals$ be a classification score function for binary
classification. 
\begin{enumerate}
\item For any example $(x,y)\in\cx\times\left\{ -1,1\right\} $, show that
\[
\ind{y\neq\sign(f(x)}\le\max\left\{ 0,1-yf(x)\right\} ,
\]
where $\sign\left(x\right)=\begin{cases}
1 & x>0\\
0 & x=0\\
-1 & x<0
\end{cases}$.
\item Show that the hinge loss $\max\left\{ 0,1-m\right\} $ is a convex
function of the margin $m$.
\item Suppose our prediction score functions are given by $f_{w}(x)=w^{T}x$.
The hinge loss of $f_{w}$ on any example $\left(x,y\right)$ is then
$\max\left\{ 0,1-yw^{T}x\right\} $. Show that this is a convex function
of $w$. 
\end{enumerate}
\end{enumerate}

\subsection{Generalized Hinge Loss}

Consider the multiclass output space $\cy=\left\{ 1,\ldots,k\right\} $.
Suppose we have a base hypothesis space \textbf{$\ch=\left\{ h:\cx\times\cy\to\reals\right\} $
}from which we select a compatibility score function. Then our final
multiclass hypothesis space is $\cf=\left\{ f(x)=\argmax_{y\in\cy}h(x,y)\mid h\in\ch\right\} $.
Since functions in $\cf$ map into $\cy$, our action space $\ca$
and output space $\cy$ are the same. Nevertheless, we will write
our class-sensitive loss function as $\Delta:\cy\times\ca\to\reals$,
even though $\cy=\ca$. We do this to indicate that the true class
goes in the first slot of the function, while the prediction (i.e.
the action) goes in the second slot. This is important because we
do not assume that $\Delta(y,y')=\Delta(y',y)$. It would not be unusual
to have this asymmetry in practice. For example, false alarms may
be much less costly than no alarm when indeed something is going wrong.

Our ultimate goal would be to find $f\in\cf$ minimizing the empirical
cost-sensitive loss:
\[
\min_{f\in\cf}\sum_{i=1}^{n}\Delta\left(y_{i},f(x_{i})\right).
\]
Since binary classification with $0/1$ loss is both intractable and
a special case of this formulation, we know that this more general
formulation must also be computationally intractable. Thus we are
looking for a convex surrogate loss function.
\begin{enumerate}
\item Suppose we have chosen an $h\in\ch$, from which we get the decision
function $f(x)=\argmax_{y\in\cy}h(x,y)$. Justify that for any $x\in\cx$
and $y\in\cy$, we have 
\[
h(x,y)\le h(x,f(x)).
\]
\item Justify the following two inequalities:
\begin{eqnarray*}
\Delta\left(y,f(x)\right) & \le & \Delta\left(y,f(x)\right)+h(x,f(x))-h(x,y)\\
 & \le & \max_{y'\in\cy}\left[\Delta\left(y,y'\right)+h(x,y')-h(x,y)\right]
\end{eqnarray*}
The RHS of the last expression is called the \textbf{generalized hinge
loss:}
\[
\ell\left(h,\left(x,y\right)\right)=\max_{y'\in\cy}\left[\Delta\left(y,y'\right)+h(x,y')-h(x,y)\right].
\]
We have shown that for any $x\in\cx,y\in\cy,h\in\ch$ we have
\[
\ell\left(h,(x,y)\right)\ge\Delta(y,f(x)),
\]
where, as usual, $f(x)=\argmax_{y\in\cy}h(x,y)$. {[}You should think
about why we cannot write the generalized hinge loss as $\ell\left(f,(x,y)\right)$.{]}
\item We now introduce a specific base hypothesis space $\ch$ of linear
functions. Consider a class-sensitive feature mapping $\Psi:\cx\times\cy\to\reals^{d}$,
and $\ch=\left\{ h_{w}\left(x,y\right)=\left\langle w,\Psi(x,y)\right\rangle \mid w\in\reals^{d}\right\} $.
Show that we can write the generalized hinge loss for $h_{w}(x,y)$
on example $\left(x_{i},y_{i}\right)$ as
\[
\ell\left(h_{w},(x_{i},y_{i})\right)=\max_{y\in\cy}\left[\Delta\left(y_{i},y\right)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle \right].
\]
\item We will now show that the generalized hinge loss $\ell\left(h_{w},(x_{i},y_{i})\right)$
is a convex function of $w$. Justify each of the following steps.
\begin{enumerate}
\item The expression $\Delta(y_{i},y)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle $
is an affine function of $w$.
\item The expression $\max_{y\in\cy}\left[\Delta\left(y_{i},y)\right)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle \right]$
is a convex function of $w$. 
\end{enumerate}
\item Conclude that $\ell\left(h_{w},(x_{i},y_{i})\right)$ is a convex
surrogate for $\Delta(y_{i},f_{w}(x_{i}))$.
\end{enumerate}

\section{SGD for Multiclass SVM}

Suppose our output space and our action space are given as follows:
$\cy=\ca=\left\{ 1,\ldots,k\right\} $. Given a non-negative class-sensitive
loss function $\Delta:\cy\times\ca\to\reals^{\ge0}$ and a class-sensitive
feature mapping $\Psi:\cx\times\cy\to\reals^{d}$. Our prediction
function $f:\cx\to\cy$ is given by
\[
f_{w}(x)=\argmax_{y\in\cy}\left\langle w,\Psi(x,y)\right\rangle 
\]
 
\begin{enumerate}
\item For a training set $(x_{1},y_{1}),\ldots(x_{n},y_{n})$, let $J(w)$
be the $\ell_{2}$-regularized empirical risk function for the multiclass
hinge loss. We can write this as
\[
J(w)=\lambda\|w\|^{2}+\frac{1}{n}\sum_{i=1}^{n}\max_{y\in\cy}\left[\Delta\left(y_{i},y\right)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle \right],
\]
for some $\lambda>0$. We will now show that $J(w)$ is a convex function
of $w$. Justify each of the following steps. As we've shown it in
a previous problem, you may use the fact that $w\mapsto\max_{y\in\cy}\left[\Delta\left(y_{i},y\right)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle \right]$
is a convex function.
\begin{enumerate}
\item $\frac{1}{n}\sum_{i=1}^{n}\max_{y\in\cy}\left[\Delta\left(y_{i},y\right)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle \right]$
is a convex function of $w$.
\item $\|w\|^{2}$ is a convex function of $w$.
\item $J(w)$ is a convex function of $w$.
\end{enumerate}
\item Since $J(w)$ is convex, it has a subgradient at every point. Give
an expression for a subgradient of $J(w)$. You may use any standard
results about subgradients, including the result from an earlier homework
about subgradients of the pointwise maxima of functions. (Hint: It
may be helpful to refer to $\hat{y}_{i}=\argmax_{y\in\cy}\left[\Delta\left(y_{i},y\right)+\left\langle w,\Psi(x_{i},y)-\Psi(x_{i},y_{i})\right\rangle \right]$.)
\item Give an expression the stochastic subgradient based on the point $(x_{i},y_{i})$.
\item Give an expression for a minibatch subgradient, based on the points
$(x_{i},y_{i}),\ldots,\left(x_{i+m-1},y_{i+m-1}\right)$. 
\end{enumerate}

\section{{[}OPTIONAL{]} Another Formulation of Generalized Hinge Loss}

In lecture we defined the \textbf{margin} of the compatibility score
function $h$ on the $i$th example $(x_{i},y_{i})$ for class $y$
as
\[
m_{i,y}(h)=h(x_{i},y_{i})-h(x_{i},y),
\]
 and the loss on an individual example $\left(x_{i},y_{i}\right)$
to be:

\[
\max_{y}\left(\left[\Delta(y_{i},y)-m_{i,y}(h)\right]_{+}\right).
\]
Here we investigate whether this is just an instance of the generalized
hinge loss $\ell\left(h,\left(x,y\right)\right)$ defined above.
\begin{enumerate}
\item Show that $\ell\left(h,\left(x_{i},y_{i}\right)\right)=\max_{y'\in\cy}\left[\Delta\left(y_{i},y'\right)-m_{i,y'}(h)\right]$.
(In other words, it looks just like loss above, but without the positive
part.) 
\item Suppose $\Delta\left(y,y'\right)\ge0$ for all $y,y'\in\cy$. Show
that for any example $\left(x_{i},y_{i}\right)$ and any score function
$h$, the multiclass hinge loss we gave in lecture and the generalized
hinge loss presented above are equivalent, in the sense that
\[
\max_{y\in\cy}\left(\left[\Delta(y_{i},y)-m_{i,y}(h)\right]_{+}\right)=\max_{y\in\cy}\left(\Delta(y_{i},y)-m_{i,y}(h)\right).
\]
(Hint: This is easy by piecing together other results we have already
attained regarding the relationship between $\ell$ and $\Delta$.)
\item In the context of the generalized hinge loss, $\Delta(y,y')$ is like
the ``target margin'' between the score for true class $y$ and
the score for class $y'$. Suppose that our prediction function $f$
gets the correct class on $x_{i}$. That is, $f(x_{i})=\argmax_{y'\in\cy}h(x_{i},y')=y_{i}$.
Furthermore, assume that all of our target margins are reached or
exceeded. That is
\[
m_{i,y}(h)=h(x_{i},y_{i})-h(x_{i},y)\ge\Delta(y_{i},y),
\]
for all $y\neq y_{i}$. It seems like in this case, we should have
$0$ loss. This is almost the case. Show that $\ell\left(h,(x_{i},y_{i})\right)=0$
if we assume that $\Delta\left(y,y\right)=0$ for all $y\in\cy$. 
\end{enumerate}

\section{{[}OPTIONAL{]} Hinge Loss is a Special Case of Generalized Hinge
Loss}

Let $\cy=\left\{ -1,1\right\} $. Let $\Delta(y,\hat{y})=\ind{y\neq\hat{y}}.$
If $g(x)$ is the score function in our binary classification setting,
then define our compatibility function as 
\begin{eqnarray*}
h(x,1) & = & g(x)/2\\
h(x,-1) & = & -g(x)/2.
\end{eqnarray*}
Show that for this choice of $h$, the multiclass hinge loss reduces
to hinge loss: 
\[
\ell\left(h,\left(x,y\right)\right)=\max_{y'\in\cy}\left[\Delta\left(y,y')\right)+h(x,y')-h(x,y)\right]=\max\left\{ 0,1-yg(x)\right\} 
\]


\section{Multiclass Classification - Implementation}

In this problem we will work on a simple three-class classification
example, similar to the one \href{https://davidrosenberg.github.io/mlcourse/Archive/2016/Lectures/9a.multiclass.pdf\#page=10}{given in lecture}.
The data is generated and plotted for you in the skeleton code. 

\subsection{One-vs-All (also known as One-vs-Rest)}

In this problem we will implement one-vs-all multiclass classification.
Our approach will assume we have a binary base classifier that returns
a score, and we will predict the class that has the highest score. 
\begin{enumerate}
\item Complete the class OneVsAllClassifier in the skeleton code. Following
the OneVsAllClassifier code is a cell that extracts the results of
the fit and plots the decision region. Include these results in your
submission.
\item {[}Optional{]} Normalize the vectors corresponding to each of the
linear SVM classifiers so that they have unit norm. Evaluate the results
and plot the decision regions for these normalized vectors.
\item {[}Optional{]} You may notice that every time you run the cell that
fits the models and plots the decision regions, you get slightly different
results. This is more pronounced when $C$ is larger, e.g. $C=200$.
Investigate and propose an explanation for this. You may use any means
necessary, including google searching and asking other people (just
like in real life). {[}It's generally good to investigate things that
look odd \textendash{} you'll almost always learn something, and sometimes
you'll uncover a more serious underlying problem.{]}
\end{enumerate}

\subsection{Multiclass SVM}

In this question, we will implement stochastic subgradient descent
for the linear multiclass SVM described in lecture and in this problem
set. We will use the class-sensitive feature mapping approach with
the ``multivector construction'', as described in our \href{https://davidrosenberg.github.io/mlcourse/Lectures/7a.multiclass.pdf\#page=27}{multiclass classification lecture}
and in SSBD Section 17.2.1. 
\begin{enumerate}
\item Complete the skeleton code for multiclass SVM. Following the multiclass
SVM implementation, we have included another block of test code. Make
sure to include the results from these tests in your assignment, along
with your code. 
\end{enumerate}

\section{{[}Optional{]} Audio Classification}

In this problem, we will work on the urban sound dataset \href{https://serv.cusp.nyu.edu/projects/urbansounddataset/urbansound8k.html}{URBANSOUND8K}
from the Center for Urban Science and Progress (CUSP) at NYU. We will
first extract features from raw audio data using the \href{https://github.com/librosa/librosa}{LibROSA}
package, and then we will train multiclass classifiers to classify
the sounds into 10 sound classes. URBANSOUND8K dataset contains 8732
labeled sound excerpts. For this problem, you may use the file UrbanSound8K.csv
to randomly sample 2000 examples for training and 2000 examples for
validation.
\begin{enumerate}
\item In LibROSA, there are many functions for visualizing audio waves and
spectra, such as display.waveplot() and display.specshow(). Load a
random audio file from each class as a floating point time series
with librosa.load(), and plot their waves and \href{https://librosa.github.io/librosa/generated/librosa.display.specshow.html}{linear-frequency power spectrogram}.
If you are interested, you can also play the audio in the notebook
with functions display() and Audio() in IPython.display. 
\item \href{https://en.wikipedia.org/wiki/Mel-frequency_cepstrum}{Mel-frequency cepstral coefficients (MFCC)}
are a commonly used feature for sound processing. We will use MFCC
and its first and second differences (like discrete derivatives) as
our features for classfication. First, use function feature.mfcc()
from LibROSA to extract MFCC features from each audio sample. (The
first MFCC coefficient is typically discarded in sound analysis, but
you do not need to. You can test whether this helps in the optional
problem below.) Next, use function feature.delta() to calculate the
first and second differences of MFCC. Finally, combine these features
and normalize each feature to zero mean and unit variance.
\item Train a linear multiclass SVM on your 2000 example training set. Evaluate
your results on the validation set in terms of 0/1 error and generate
a confusion table. Compare the results to a one-vs-all classifier
using a binary linear SVM as the base classifier. For each model,
may use your code from the previous problem, or you may use another
implementation (e.g. from sklearn). 
\item {[}More Optional{]} Compare results to any other multiclass classification
methods of your choice. 
\item {[}More Optional{]} Try different feature sets and see how they affect
performance.
\end{enumerate}

\end{document}
